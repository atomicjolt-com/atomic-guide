# Story 5.1 Test Design Strategy
## Struggle Detection + Proactive Chat Interventions

**Created:** 2025-09-06  
**QA Agent:** Claude Code QA  
**Story:** 5.1 - Struggle Detection + Proactive Chat Interventions  
**Risk Level:** MEDIUM-HIGH (manageable with comprehensive testing)  

---

## Executive Summary

This document provides a comprehensive test design strategy for Story 5.1, addressing the quality risks identified in the QA review. The strategy focuses on ML model accuracy, real-time performance validation, Canvas integration security, and privacy compliance testing.

**Key Testing Priorities:**
1. **ML Model Accuracy Validation** - Struggle detection precision >70%, comprehensive bias testing
2. **Real-Time Performance Testing** - Durable Objects <100ms latency under 1000+ concurrent users  
3. **Canvas Integration Security** - PostMessage security, cross-browser compatibility
4. **Privacy Compliance Validation** - FERPA/GDPR compliance, consent enforcement

---

## 1. Test Strategy Overview

### 1.1 Testing Approach

**Test Pyramid Structure:**
```
                    ┌─────────────────┐
                    │   E2E Tests     │ <- 10% (Critical user journeys)
                    │   (Playwright)  │
                ┌───┴─────────────────┴───┐
                │  Integration Tests      │ <- 30% (API, DB, Canvas)
                │  (Vitest + Mocks)      │
            ┌───┴─────────────────────────┴───┐
            │     Unit Tests                  │ <- 60% (Business logic)
            │  (Vitest + Test Factories)     │
            └─────────────────────────────────┘
```

**Quality Gates:**
- Unit Test Coverage: >80% for all new components
- Integration Test Coverage: >90% of critical user journeys  
- E2E Test Coverage: 100% of acceptance criteria
- Performance Test Coverage: All real-time components
- Security Test Coverage: All Canvas integration points

### 1.2 Test Environment Matrix

| Environment | Purpose | Data | Canvas Setup |
|------------|---------|------|-------------|
| **Unit** | Component isolation | Mock/Factory | Mock postMessage |
| **Integration** | Service coordination | Test DB | Canvas sandbox |
| **Staging** | End-to-end validation | Synthetic data | Production Canvas |
| **Load Testing** | Performance validation | Synthetic load | Isolated Canvas |
| **Security** | Penetration testing | Synthetic data | Mock malicious origins |

---

## 2. ML Model Testing Strategy

### 2.1 Struggle Prediction Accuracy Validation

**Objective:** Validate >70% precision in struggle detection with comprehensive bias testing

#### 2.1.1 Test Data Generation Strategy

```typescript
// Test data factory for struggle scenarios
interface StruggleTestScenario {
  scenarioName: string;
  expectedStruggle: boolean;
  behavioralSignals: BehavioralSignal[];
  groundTruthLabel: 'struggling' | 'not_struggling';
  demographicContext?: {
    ageGroup: 'traditional' | 'non_traditional';
    priorExperience: 'novice' | 'intermediate' | 'advanced';
    courseType: 'stem' | 'liberal_arts' | 'professional';
  };
}

export const struggleScenarioFactory = {
  // High struggle indicators
  clearStrugglePattern: (): StruggleTestScenario => ({
    scenarioName: 'Clear Struggle Pattern',
    expectedStruggle: true,
    groundTruthLabel: 'struggling',
    behavioralSignals: [
      { type: 'hover', duration: 45000, element: 'quiz-question-1' }, // Long hover
      { type: 'scroll', frequency: 15, pattern: 'repeated_area' }, // Repetitive scrolling
      { type: 'idle', duration: 60000 }, // Extended idle period
      { type: 'help_request', count: 4 }, // Multiple help requests
      { type: 'error', count: 8, pattern: 'same_concept' }, // Repeated errors
    ]
  }),

  // Low struggle indicators  
  normalLearningPattern: (): StruggleTestScenario => ({
    scenarioName: 'Normal Learning Pattern',
    expectedStruggle: false,
    groundTruthLabel: 'not_struggling',
    behavioralSignals: [
      { type: 'hover', duration: 8000, element: 'quiz-question-1' }, // Normal hover
      { type: 'scroll', frequency: 3, pattern: 'linear_progression' }, // Progressive scrolling
      { type: 'idle', duration: 5000 }, // Brief pause
      { type: 'help_request', count: 1 }, // Single help request
      { type: 'error', count: 2, pattern: 'different_concepts' }, // Normal errors
    ]
  }),

  // Edge cases
  ambiguousPattern: (): StruggleTestScenario => ({
    scenarioName: 'Ambiguous Pattern - Thoughtful Learner',
    expectedStruggle: false,
    groundTruthLabel: 'not_struggling',
    behavioralSignals: [
      { type: 'hover', duration: 35000, element: 'complex-diagram' }, // Long hover on complex content
      { type: 'scroll', frequency: 8, pattern: 'reference_checking' }, // Reference scrolling
      { type: 'idle', duration: 25000 }, // Thinking time
      { type: 'help_request', count: 0 }, // No help requests
      { type: 'error', count: 1, pattern: 'minor_typo' }, // Single minor error
    ]
  })
};
```

#### 2.1.2 Accuracy Testing Framework

```typescript
describe('Struggle Prediction Accuracy', () => {
  let accuracyValidator: StruggleAccuracyValidator;
  let testDataset: StruggleTestScenario[];

  beforeAll(async () => {
    // Generate comprehensive test dataset
    testDataset = generateStruggleTestDataset(1000); // 1000 scenarios
    accuracyValidator = new StruggleAccuracyValidator();
  });

  it('should achieve >70% precision in struggle detection', async () => {
    const results = await accuracyValidator.validatePredictionAccuracy(testDataset);
    
    expect(results.precision).toBeGreaterThan(0.70);
    expect(results.recall).toBeGreaterThan(0.65);
    expect(results.f1Score).toBeGreaterThan(0.67);
    expect(results.falsePositiveRate).toBeLessThan(0.15);
    
    // Log detailed results for analysis
    console.log('Accuracy Results:', {
      precision: results.precision,
      recall: results.recall,
      f1Score: results.f1Score,
      confusionMatrix: results.confusionMatrix
    });
  });

  it('should maintain accuracy across demographic groups', async () => {
    const demographicGroups = ['traditional', 'non_traditional'];
    const experienceLevels = ['novice', 'intermediate', 'advanced'];
    const courseTypes = ['stem', 'liberal_arts', 'professional'];

    for (const demographic of demographicGroups) {
      for (const experience of experienceLevels) {
        for (const courseType of courseTypes) {
          const subset = testDataset.filter(scenario => 
            scenario.demographicContext?.ageGroup === demographic &&
            scenario.demographicContext?.priorExperience === experience &&
            scenario.demographicContext?.courseType === courseType
          );

          if (subset.length > 10) { // Minimum sample size
            const results = await accuracyValidator.validatePredictionAccuracy(subset);
            
            // Check for bias - no group should have significantly lower accuracy
            expect(results.precision).toBeGreaterThan(0.60); // Minimum threshold
            expect(Math.abs(results.precision - 0.70)).toBeLessThan(0.20); // Fairness threshold
          }
        }
      }
    }
  });

  it('should provide confidence calibration', async () => {
    const predictions = await Promise.all(
      testDataset.map(scenario => recognizer.predictStruggle(
        'tenant-1', 'user-1', 'course-1', scenario.behavioralSignals
      ))
    );

    // High confidence predictions should be more accurate
    const highConfidencePredictions = predictions.filter(p => p.confidence > 0.8);
    const lowConfidencePredictions = predictions.filter(p => p.confidence < 0.4);

    const highConfAccuracy = calculateAccuracy(highConfidencePredictions, testDataset);
    const lowConfAccuracy = calculateAccuracy(lowConfidencePredictions, testDataset);

    expect(highConfAccuracy).toBeGreaterThan(lowConfAccuracy);
    expect(highConfAccuracy).toBeGreaterThan(0.85);
  });
});
```

### 2.2 Model Performance Validation

#### 2.2.1 Prediction Latency Testing

```typescript
describe('ML Model Performance', () => {
  it('should generate predictions within performance targets', async () => {
    const behavioralSignals = generateRealisticSignals(50); // 50 signals
    
    const startTime = Date.now();
    const prediction = await recognizer.predictStruggle('tenant-1', 'user-1', 'course-1', behavioralSignals);
    const elapsedTime = Date.now() - startTime;

    // Performance requirement: <10 seconds for prediction generation
    expect(elapsedTime).toBeLessThan(10000);
    expect(prediction.timeToStruggle).toBeGreaterThan(0);
    expect(prediction.riskLevel).toBeGreaterThanOrEqual(0);
    expect(prediction.riskLevel).toBeLessThanOrEqual(1);
  });

  it('should handle concurrent prediction requests efficiently', async () => {
    const concurrentRequests = 20;
    const requests = Array.from({ length: concurrentRequests }, (_, i) => 
      recognizer.predictStruggle(`tenant-${i}`, `user-${i}`, `course-${i}`)
    );

    const startTime = Date.now();
    const results = await Promise.all(requests);
    const totalTime = Date.now() - startTime;
    const avgTimePerPrediction = totalTime / concurrentRequests;

    expect(avgTimePerPrediction).toBeLessThan(8000); // Average under 8s
    expect(results).toHaveLength(concurrentRequests);
    results.forEach(result => {
      expect(result.riskLevel).toBeGreaterThanOrEqual(0);
      expect(result.confidence).toBeGreaterThanOrEqual(0);
    });
  });
});
```

---

## 3. Performance Testing Requirements

### 3.1 Durable Objects Load Testing

**Objective:** Validate <100ms latency under 1000+ concurrent users with 10+ signals/second per session

#### 3.1.1 Load Testing Scenarios

```typescript
interface LoadTestScenario {
  name: string;
  concurrentUsers: number;
  signalsPerSecond: number;
  durationMinutes: number;
  successCriteria: {
    latencyP95: number; // milliseconds
    errorRate: number; // percentage
    memoryUsage: number; // MB per DO
    cpuUtilization: number; // percentage
  };
}

export const loadTestScenarios: LoadTestScenario[] = [
  {
    name: 'Normal Load',
    concurrentUsers: 100,
    signalsPerSecond: 5,
    durationMinutes: 10,
    successCriteria: {
      latencyP95: 50,
      errorRate: 0.01,
      memoryUsage: 200,
      cpuUtilization: 60
    }
  },
  {
    name: 'Peak Load',
    concurrentUsers: 1000,
    signalsPerSecond: 10,
    durationMinutes: 15,
    successCriteria: {
      latencyP95: 100,
      errorRate: 0.1,
      memoryUsage: 500,
      cpuUtilization: 80
    }
  },
  {
    name: 'Spike Load',
    concurrentUsers: 2000,
    signalsPerSecond: 15,
    durationMinutes: 5,
    successCriteria: {
      latencyP95: 150,
      errorRate: 0.5,
      memoryUsage: 600,
      cpuUtilization: 90
    }
  }
];
```

#### 3.1.2 Performance Testing Implementation

```typescript
describe('Durable Objects Performance', () => {
  let loadTestHarness: DurableObjectLoadTester;

  beforeAll(() => {
    loadTestHarness = new DurableObjectLoadTester();
  });

  loadTestScenarios.forEach(scenario => {
    it(`should meet performance criteria under ${scenario.name}`, async () => {
      const testConfig = {
        concurrentUsers: scenario.concurrentUsers,
        signalsPerSecond: scenario.signalsPerSecond,
        durationMs: scenario.durationMinutes * 60 * 1000
      };

      const results = await loadTestHarness.runLoadTest(testConfig);

      // Latency requirements
      expect(results.latency.p95).toBeLessThan(scenario.successCriteria.latencyP95);
      expect(results.latency.p99).toBeLessThan(scenario.successCriteria.latencyP95 * 1.5);

      // Error rate requirements
      expect(results.errorRate).toBeLessThan(scenario.successCriteria.errorRate);

      // Resource utilization
      expect(results.memoryUsage.peak).toBeLessThan(scenario.successCriteria.memoryUsage);
      expect(results.cpuUtilization.average).toBeLessThan(scenario.successCriteria.cpuUtilization);

      // Auto-scaling validation
      expect(results.durableObjectInstances).toBeGreaterThan(scenario.concurrentUsers / 100);
    }, 30000); // 30 second timeout for load tests
  });

  it('should handle Durable Object restart scenarios', async () => {
    // Start normal load
    const loadTest = loadTestHarness.startContinuousLoad({
      concurrentUsers: 100,
      signalsPerSecond: 5
    });

    // Simulate DO restart after 2 minutes
    setTimeout(() => loadTestHarness.simulateDoRestart(), 120000);

    // Run for 5 minutes total
    const results = await loadTest.runFor(300000);

    // State recovery validation
    expect(results.dataLossEvents).toBe(0);
    expect(results.recoveryTime).toBeLessThan(30000); // <30s recovery
    expect(results.postRecoveryLatency.p95).toBeLessThan(200); // Acceptable degradation
  });
});
```

### 3.2 Memory Leak and Resource Testing

```typescript
describe('Resource Management', () => {
  it('should not have memory leaks during extended operation', async () => {
    const memoryTracker = new MemoryLeakDetector();
    const signalGenerator = new BehavioralSignalGenerator();

    // Run for 2 hours with continuous signals
    const testDuration = 2 * 60 * 60 * 1000; // 2 hours
    const startTime = Date.now();
    let memorySnapshots: number[] = [];

    while (Date.now() - startTime < testDuration) {
      // Generate realistic behavioral signals
      const signals = signalGenerator.generateRealisticBatch();
      await recognizer.processSignals(signals);

      // Take memory snapshot every 10 minutes
      if ((Date.now() - startTime) % (10 * 60 * 1000) < 1000) {
        memorySnapshots.push(memoryTracker.getCurrentUsage());
      }

      await new Promise(resolve => setTimeout(resolve, 1000)); // 1 second interval
    }

    // Analyze memory trend
    const memoryTrend = memoryTracker.analyzeTrend(memorySnapshots);
    expect(memoryTrend.growthRate).toBeLessThan(0.01); // <1% growth rate
    expect(memoryTrend.leakDetected).toBe(false);
  });

  it('should cleanup sessions properly', async () => {
    const sessionManager = new SessionManager();
    const initialSessions = sessionManager.getActiveSessionCount();

    // Create 100 sessions
    const sessions = await Promise.all(
      Array.from({ length: 100 }, (_, i) => 
        sessionManager.createSession(`user-${i}`)
      )
    );

    expect(sessionManager.getActiveSessionCount()).toBe(initialSessions + 100);

    // End all sessions
    await Promise.all(sessions.map(session => sessionManager.endSession(session.id)));

    // Wait for cleanup
    await new Promise(resolve => setTimeout(resolve, 5000));

    expect(sessionManager.getActiveSessionCount()).toBe(initialSessions);
  });
});
```

---

## 4. Canvas Integration Testing Matrix

### 4.1 Cross-Browser and Environment Testing

**Objective:** Validate Canvas postMessage integration across browsers and Canvas environments

#### 4.1.1 Browser Compatibility Matrix

| Browser | Version | Canvas Support | PostMessage API | MessageChannel | Security Features |
|---------|---------|----------------|-----------------|----------------|-------------------|
| **Chrome** | 90+ | ✅ Full | ✅ Full | ✅ Yes | ✅ CSP, CORS |
| **Firefox** | 88+ | ✅ Full | ✅ Full | ✅ Yes | ✅ CSP, CORS |
| **Safari** | 14+ | ⚠️ Limited | ✅ Full | ✅ Yes | ⚠️ Partial CSP |
| **Edge** | 90+ | ✅ Full | ✅ Full | ✅ Yes | ✅ CSP, CORS |
| **Mobile Chrome** | 90+ | ⚠️ Limited | ✅ Partial | ❌ No | ⚠️ Limited |
| **Mobile Safari** | 14+ | ⚠️ Limited | ⚠️ Partial | ❌ No | ❌ Limited |

#### 4.1.2 Canvas Environment Testing

```typescript
interface CanvasEnvironment {
  name: string;
  domain: string;
  version: string;
  features: string[];
  limitations: string[];
}

export const canvasEnvironments: CanvasEnvironment[] = [
  {
    name: 'Canvas Cloud',
    domain: 'canvas.instructure.com',
    version: 'latest',
    features: ['postMessage', 'deepLinking', 'namesRoles'],
    limitations: []
  },
  {
    name: 'Institution Hosted',
    domain: '*.instructure.com',
    version: 'varies',
    features: ['postMessage', 'deepLinking'],
    limitations: ['limited-api-access']
  },
  {
    name: 'Canvas Community',
    domain: 'community.canvaslms.com',
    version: 'open-source',
    features: ['basic-postMessage'],
    limitations: ['no-deep-linking', 'limited-api']
  }
];
```

#### 4.1.3 Integration Testing Implementation

```typescript
describe('Canvas PostMessage Integration', () => {
  canvasEnvironments.forEach(environment => {
    describe(`${environment.name} Environment`, () => {
      let canvasSimulator: CanvasEnvironmentSimulator;

      beforeEach(() => {
        canvasSimulator = new CanvasEnvironmentSimulator(environment);
      });

      it('should establish secure communication channel', async () => {
        const postMessageService = new CanvasPostMessageService();
        
        // Simulate Canvas environment
        const canvasFrame = canvasSimulator.createCanvasFrame();
        const messageChannel = await postMessageService.establishSecureChannel(canvasFrame);

        expect(messageChannel.port1).toBeDefined();
        expect(messageChannel.port2).toBeDefined();
        expect(postMessageService.isSecureChannelEstablished()).toBe(true);
      });

      it('should handle origin validation correctly', async () => {
        const securityHandler = new SecureMessageHandler();
        
        // Test trusted origins
        const trustedMessage = {
          origin: environment.domain,
          data: { type: 'behavioral.signal', data: {} }
        };
        expect(() => securityHandler.handleMessage(trustedMessage)).not.toThrow();

        // Test untrusted origins
        const untrustedOrigins = [
          'https://evil.com',
          'https://instructure.com.evil.com',
          'https://evil.instructure.com.hacker.com'
        ];

        untrustedOrigins.forEach(origin => {
          const untrustedMessage = { origin, data: { type: 'behavioral.signal' } };
          expect(() => securityHandler.handleMessage(untrustedMessage)).toThrow('Untrusted origin');
        });
      });

      it('should extract page content accurately', async () => {
        const contentExtractor = new CanvasContentExtractor();
        
        // Test different Canvas page types
        const pageTypes = [
          { type: 'assignment', hasContent: true },
          { type: 'quiz', hasContent: true },
          { type: 'discussion', hasContent: true },
          { type: 'module', hasContent: true },
          { type: 'dashboard', hasContent: false }
        ];

        for (const pageType of pageTypes) {
          canvasSimulator.simulatePageType(pageType.type);
          
          const content = await contentExtractor.extractPageContent();
          
          if (pageType.hasContent) {
            expect(content.text.length).toBeGreaterThan(0);
            expect(content.metadata.pageType).toBe(pageType.type);
          }
          
          expect(content.extractionMethod).toMatch(/(canvas-api|dom-fallback)/);
        }
      });

      it('should handle Canvas API limitations gracefully', async () => {
        const apiLimitations = environment.limitations;
        
        if (apiLimitations.includes('limited-api-access')) {
          // Test fallback mechanisms
          const contentExtractor = new CanvasContentExtractor();
          canvasSimulator.simulateApiLimitation('getPageContent');
          
          const content = await contentExtractor.extractPageContent();
          
          expect(content.extractionMethod).toBe('dom-fallback');
          expect(content.text).toBeDefined(); // Should still extract content
        }
      });
    });
  });
});
```

### 4.2 Security Testing

#### 4.2.1 PostMessage Security Validation

```typescript
describe('PostMessage Security', () => {
  let securityTester: PostMessageSecurityTester;

  beforeEach(() => {
    securityTester = new PostMessageSecurityTester();
  });

  it('should reject origin bypass attempts', async () => {
    const bypassAttempts = [
      'https://evil.instructure.com.attacker.com',
      'https://instructure.com.evil.com',
      'https://sub.instructure.com.attacker.net',
      'http://instructure.com', // HTTP instead of HTTPS
      'instructure.com', // Missing protocol
      'https://instructure.co.uk' // Similar but different domain
    ];

    bypassAttempts.forEach(maliciousOrigin => {
      const maliciousMessage = {
        origin: maliciousOrigin,
        data: { type: 'behavioral.signal', payload: 'malicious' }
      };

      expect(() => securityTester.validateOrigin(maliciousMessage))
        .toThrow('Origin validation failed');
    });
  });

  it('should validate message integrity', async () => {
    const messageValidator = new MessageIntegrityValidator();
    
    // Test HMAC signature validation
    const validMessage = {
      type: 'behavioral.signal',
      data: { duration: 5000 },
      timestamp: Date.now(),
      signature: messageValidator.generateHMAC({ duration: 5000 })
    };

    expect(messageValidator.validateMessage(validMessage)).toBe(true);

    // Test tampered message
    const tamperedMessage = { ...validMessage };
    tamperedMessage.data.duration = 999999; // Tampered data
    
    expect(messageValidator.validateMessage(tamperedMessage)).toBe(false);
  });

  it('should prevent replay attacks', async () => {
    const replayProtection = new ReplayProtectionService();
    
    const message = {
      type: 'behavioral.signal',
      data: { duration: 5000 },
      timestamp: Date.now(),
      nonce: 'unique-nonce-123'
    };

    // First message should succeed
    expect(await replayProtection.validateMessage(message)).toBe(true);

    // Replay should fail
    expect(await replayProtection.validateMessage(message)).toBe(false);

    // Old message should fail
    const oldMessage = {
      ...message,
      timestamp: Date.now() - (10 * 60 * 1000), // 10 minutes old
      nonce: 'unique-nonce-124'
    };
    expect(await replayProtection.validateMessage(oldMessage)).toBe(false);
  });

  it('should enforce rate limiting', async () => {
    const rateLimiter = new MessageRateLimiter({
      maxMessagesPerSecond: 10,
      burstSize: 50,
      windowSizeMs: 1000
    });

    // Normal rate should succeed
    for (let i = 0; i < 10; i++) {
      expect(rateLimiter.checkLimit('user-1')).toBe(true);
    }

    // Exceed rate limit
    expect(rateLimiter.checkLimit('user-1')).toBe(false);

    // Wait for window reset
    await new Promise(resolve => setTimeout(resolve, 1100));
    expect(rateLimiter.checkLimit('user-1')).toBe(true);
  });
});
```

---

## 5. Privacy Compliance Testing

### 5.1 FERPA/GDPR Compliance Validation

**Objective:** Ensure all behavioral data processing complies with privacy regulations and consent requirements

#### 5.1.1 Consent Validation Testing

```typescript
describe('Privacy Compliance', () => {
  let privacyService: PrivacyControlService;
  let complianceValidator: PrivacyComplianceValidator;

  beforeEach(() => {
    privacyService = new PrivacyControlService();
    complianceValidator = new PrivacyComplianceValidator();
  });

  it('should enforce consent requirements for all data processing', async () => {
    const testScenarios = [
      {
        consentLevel: 'none',
        operations: ['predictStruggle', 'analyzeBehavioralSignals', 'generateInterventions'],
        expectedResult: 'PRIVACY_ERROR'
      },
      {
        consentLevel: 'basic',
        operations: ['predictStruggle'],
        expectedResult: 'success'
      },
      {
        consentLevel: 'comprehensive',
        operations: ['predictStruggle', 'analyzeBehavioralSignals', 'generateInterventions'],
        expectedResult: 'success'
      }
    ];

    for (const scenario of testScenarios) {
      await privacyService.setUserConsent('user-1', scenario.consentLevel);

      for (const operation of scenario.operations) {
        if (scenario.expectedResult === 'PRIVACY_ERROR') {
          await expect(executeOperation(operation, 'user-1'))
            .rejects.toThrow('PRIVACY_ERROR');
        } else {
          await expect(executeOperation(operation, 'user-1'))
            .resolves.toBeDefined();
        }
      }
    }
  });

  it('should handle consent withdrawal properly', async () => {
    // Set up user with full consent and data
    await privacyService.setUserConsent('user-1', 'comprehensive');
    await generateUserBehavioralData('user-1');

    // Verify data exists
    const dataExists = await checkUserDataExists('user-1');
    expect(dataExists).toBe(true);

    // Withdraw consent
    await privacyService.withdrawAllConsent('user-1');

    // Verify immediate processing stops
    await expect(recognizer.predictStruggle('tenant-1', 'user-1', 'course-1'))
      .rejects.toThrow('PRIVACY_ERROR');

    // Verify data purging (within compliance timeframe)
    const purgeResult = await complianceValidator.verifyDataPurging('user-1', 30); // 30 days
    expect(purgeResult.behavioralDataPurged).toBe(true);
    expect(purgeResult.predictionsRemoved).toBe(true);
    expect(purgeResult.anonymizedAnalyticsRetained).toBe(true); // Can retain anonymized
  });

  it('should anonymize instructor alerts per privacy settings', async () => {
    const instructorAlertService = new InstructorAlertService();

    // Set user privacy to require anonymization
    await privacyService.setPrivacySetting('user-1', 'instructorAlerts', 'anonymized');

    // Generate struggle event that triggers alert
    const struggleEvent = createHighStruggleEvent('user-1');
    const alert = await instructorAlertService.generateAlert(struggleEvent);

    // Verify anonymization
    expect(alert.studentIdentifier).toMatch(/^anon-[a-f0-9]{8}$/);
    expect(alert.studentName).toBeUndefined();
    expect(alert.studentEmail).toBeUndefined();
    expect(alert.demographicInfo).toBeUndefined();

    // But should contain actionable information
    expect(alert.struggleMetrics).toBeDefined();
    expect(alert.recommendedInterventions).toBeDefined();
    expect(alert.courseContext).toBeDefined();
  });

  it('should comply with data retention policies', async () => {
    const retentionPolicies = [
      { dataType: 'behavioral_signals', retentionDays: 90 },
      { dataType: 'struggle_predictions', retentionDays: 365 },
      { dataType: 'intervention_logs', retentionDays: 1095 }, // 3 years
      { dataType: 'anonymized_analytics', retentionDays: -1 } // Indefinite
    ];

    for (const policy of retentionPolicies) {
      // Create test data older than retention period
      const testData = await createTestDataWithAge(policy.dataType, policy.retentionDays + 10);
      
      // Run retention cleanup
      await complianceValidator.runRetentionCleanup();

      // Verify data is purged (or retained if retention is indefinite)
      const dataExists = await checkTestDataExists(testData.id);
      if (policy.retentionDays === -1) {
        expect(dataExists).toBe(true); // Should retain indefinitely
      } else {
        expect(dataExists).toBe(false); // Should be purged
      }
    }
  });

  it('should maintain audit logs for compliance', async () => {
    const auditLogger = new ComplianceAuditLogger();
    
    // Perform various operations
    await recognizer.predictStruggle('tenant-1', 'user-1', 'course-1');
    await privacyService.withdrawConsent('user-1', 'behavioral_analysis');
    await instructorAlertService.sendAlert('instructor-1', 'alert-123');

    // Verify audit logs
    const auditLogs = await auditLogger.getAuditLogs('user-1', 24); // 24 hours

    expect(auditLogs.length).toBeGreaterThan(0);
    
    const predictionLog = auditLogs.find(log => log.action === 'struggle_prediction');
    expect(predictionLog).toBeDefined();
    expect(predictionLog.consentVerified).toBe(true);
    expect(predictionLog.dataProcessed).toEqual(expect.any(Array));

    const consentLog = auditLogs.find(log => log.action === 'consent_withdrawal');
    expect(consentLog).toBeDefined();
    expect(consentLog.effectiveDate).toBeDefined();
  });
});
```

---

## 6. Quality Gate Implementation

### 6.1 Automated Quality Gates

**Objective:** Define measurable acceptance criteria with automated enforcement

#### 6.1.1 Pre-Deployment Quality Gates

```typescript
interface QualityGate {
  name: string;
  metric: string;
  threshold: number;
  blocking: boolean;
  automatedCheck: boolean;
}

export const qualityGates: QualityGate[] = [
  // Performance Gates (BLOCKING)
  {
    name: 'Behavioral Signal Processing Latency',
    metric: 'p95_latency_ms',
    threshold: 100,
    blocking: true,
    automatedCheck: true
  },
  {
    name: 'Struggle Prediction Accuracy',
    metric: 'precision_percentage',
    threshold: 70,
    blocking: true,
    automatedCheck: true
  },
  {
    name: 'Canvas Integration Success Rate',
    metric: 'message_delivery_success_rate',
    threshold: 99,
    blocking: true,
    automatedCheck: true
  },
  {
    name: 'Concurrent User Support',
    metric: 'max_concurrent_users',
    threshold: 1000,
    blocking: true,
    automatedCheck: true
  },
  
  // Security Gates (BLOCKING)
  {
    name: 'Origin Validation Bypass Rate',
    metric: 'security_bypass_attempts_blocked',
    threshold: 100,
    blocking: true,
    automatedCheck: true
  },
  {
    name: 'Input Sanitization Coverage',
    metric: 'sanitization_coverage_percentage',
    threshold: 100,
    blocking: true,
    automatedCheck: true
  },
  
  // Privacy Gates (BLOCKING)
  {
    name: 'Consent Enforcement Rate',
    metric: 'consent_validation_success_rate',
    threshold: 100,
    blocking: true,
    automatedCheck: true
  },
  {
    name: 'Data Retention Compliance',
    metric: 'retention_policy_compliance_rate',
    threshold: 100,
    blocking: true,
    automatedCheck: true
  },
  
  // Quality Gates (NON-BLOCKING - Warnings)
  {
    name: 'Unit Test Coverage',
    metric: 'code_coverage_percentage',
    threshold: 80,
    blocking: false,
    automatedCheck: true
  },
  {
    name: 'Memory Usage per Durable Object',
    metric: 'peak_memory_usage_mb',
    threshold: 500,
    blocking: false,
    automatedCheck: true
  }
];
```

#### 6.1.2 Quality Gate Automation

```typescript
export class QualityGateValidator {
  private testRunner: TestRunner;
  private performanceMonitor: PerformanceMonitor;
  private securityScanner: SecurityScanner;

  constructor() {
    this.testRunner = new TestRunner();
    this.performanceMonitor = new PerformanceMonitor();
    this.securityScanner = new SecurityScanner();
  }

  async validateAllGates(): Promise<QualityGateResult[]> {
    const results: QualityGateResult[] = [];

    for (const gate of qualityGates) {
      try {
        const result = await this.validateGate(gate);
        results.push(result);

        if (gate.blocking && !result.passed) {
          throw new Error(`BLOCKING QUALITY GATE FAILED: ${gate.name} - ${result.message}`);
        }
      } catch (error) {
        results.push({
          gateName: gate.name,
          passed: false,
          actualValue: null,
          expectedValue: gate.threshold,
          message: error.message,
          blocking: gate.blocking
        });
      }
    }

    return results;
  }

  private async validateGate(gate: QualityGate): Promise<QualityGateResult> {
    switch (gate.metric) {
      case 'p95_latency_ms':
        return await this.validateLatency(gate);
      
      case 'precision_percentage':
        return await this.validateAccuracy(gate);
      
      case 'message_delivery_success_rate':
        return await this.validateCanvasIntegration(gate);
      
      case 'max_concurrent_users':
        return await this.validateConcurrency(gate);
      
      case 'security_bypass_attempts_blocked':
        return await this.validateSecurity(gate);
      
      case 'consent_validation_success_rate':
        return await this.validatePrivacy(gate);
      
      case 'code_coverage_percentage':
        return await this.validateCoverage(gate);
      
      default:
        throw new Error(`Unknown quality gate metric: ${gate.metric}`);
    }
  }

  private async validateLatency(gate: QualityGate): Promise<QualityGateResult> {
    const loadTestResults = await this.performanceMonitor.runLatencyTest();
    const p95Latency = loadTestResults.latency.p95;

    return {
      gateName: gate.name,
      passed: p95Latency <= gate.threshold,
      actualValue: p95Latency,
      expectedValue: gate.threshold,
      message: p95Latency <= gate.threshold 
        ? `Latency within threshold (${p95Latency}ms <= ${gate.threshold}ms)`
        : `Latency exceeds threshold (${p95Latency}ms > ${gate.threshold}ms)`,
      blocking: gate.blocking
    };
  }

  private async validateAccuracy(gate: QualityGate): Promise<QualityGateResult> {
    const accuracyResults = await this.testRunner.runAccuracyTests();
    const precision = accuracyResults.precision * 100; // Convert to percentage

    return {
      gateName: gate.name,
      passed: precision >= gate.threshold,
      actualValue: precision,
      expectedValue: gate.threshold,
      message: precision >= gate.threshold
        ? `Accuracy meets threshold (${precision.toFixed(1)}% >= ${gate.threshold}%)`
        : `Accuracy below threshold (${precision.toFixed(1)}% < ${gate.threshold}%)`,
      blocking: gate.blocking
    };
  }

  private async validateCanvasIntegration(gate: QualityGate): Promise<QualityGateResult> {
    const integrationResults = await this.testRunner.runCanvasIntegrationTests();
    const successRate = integrationResults.successRate * 100;

    return {
      gateName: gate.name,
      passed: successRate >= gate.threshold,
      actualValue: successRate,
      expectedValue: gate.threshold,
      message: successRate >= gate.threshold
        ? `Canvas integration success rate meets threshold (${successRate.toFixed(1)}% >= ${gate.threshold}%)`
        : `Canvas integration success rate below threshold (${successRate.toFixed(1)}% < ${gate.threshold}%)`,
      blocking: gate.blocking
    };
  }

  // Additional validation methods...
}
```

### 6.2 Continuous Quality Monitoring

#### 6.2.1 Production Quality Metrics

```typescript
export class ProductionQualityMonitor {
  private metricsCollector: MetricsCollector;
  private alertManager: AlertManager;

  constructor() {
    this.metricsCollector = new MetricsCollector();
    this.alertManager = new AlertManager();
  }

  async monitorQualityMetrics(): Promise<void> {
    // Real-time quality metrics
    const metrics = {
      strugglePredictionAccuracy: await this.measurePredictionAccuracy(),
      behavioralSignalLatency: await this.measureSignalProcessingLatency(),
      canvasIntegrationHealth: await this.measureCanvasIntegrationHealth(),
      privacyComplianceRate: await this.measurePrivacyCompliance(),
      userSatisfactionScore: await this.measureUserSatisfaction()
    };

    // Alert on quality degradation
    if (metrics.strugglePredictionAccuracy < 0.65) {
      await this.alertManager.sendAlert('QUALITY_ALERT', {
        metric: 'Struggle Prediction Accuracy',
        value: metrics.strugglePredictionAccuracy,
        threshold: 0.65,
        severity: 'HIGH'
      });
    }

    if (metrics.behavioralSignalLatency.p95 > 150) {
      await this.alertManager.sendAlert('PERFORMANCE_ALERT', {
        metric: 'Behavioral Signal Processing Latency P95',
        value: metrics.behavioralSignalLatency.p95,
        threshold: 150,
        severity: 'HIGH'
      });
    }

    // Log metrics for trending
    await this.metricsCollector.recordMetrics(metrics);
  }

  private async measurePredictionAccuracy(): Promise<number> {
    // Sample recent predictions and validate against ground truth
    const recentPredictions = await this.getRecentPredictions(100);
    const groundTruthLabels = await this.getGroundTruthLabels(recentPredictions);
    
    return calculateAccuracy(recentPredictions, groundTruthLabels);
  }

  private async measureSignalProcessingLatency(): Promise<LatencyMetrics> {
    // Monitor real-time signal processing performance
    return await this.metricsCollector.getLatencyMetrics('behavioral_signal_processing', '1h');
  }

  private async measureCanvasIntegrationHealth(): Promise<number> {
    // Monitor Canvas postMessage success rates
    const integrationMetrics = await this.metricsCollector.getIntegrationMetrics('canvas_postmessage', '1h');
    return integrationMetrics.successRate;
  }
}
```

---

## 7. Implementation Timeline

### 7.1 Test Development Phases

| Phase | Duration | Focus | Deliverables |
|-------|----------|-------|--------------|
| **Phase 1** | Week 1-2 | Unit Testing Infrastructure | Test factories, mock services, 80% unit coverage |
| **Phase 2** | Week 2-3 | ML Model Validation | Accuracy testing, bias detection, performance validation |
| **Phase 3** | Week 3-4 | Performance Testing | Load testing, memory validation, Durable Object scaling |
| **Phase 4** | Week 4-5 | Canvas Integration Testing | Cross-browser, security testing, environment validation |
| **Phase 5** | Week 5-6 | End-to-End Testing | Complete user journeys, regression testing, quality gates |
| **Phase 6** | Week 6+ | Production Monitoring | Quality metrics, continuous validation, alerting |

### 7.2 Success Criteria

#### 7.2.1 Mandatory Pre-Launch Requirements

- [ ] **Performance:** P95 latency <100ms under 1000 concurrent users
- [ ] **Accuracy:** Struggle prediction precision >70%, recall >65%
- [ ] **Security:** 100% origin validation, zero bypass attempts successful
- [ ] **Privacy:** 100% consent enforcement, compliant data handling
- [ ] **Integration:** >99% Canvas message delivery success rate
- [ ] **Coverage:** >80% unit test coverage, >90% integration coverage

#### 7.2.2 Quality Metrics Targets

- [ ] **Reliability:** >99.9% system availability during testing
- [ ] **Memory:** No memory leaks in 8-hour stress tests
- [ ] **Recovery:** <30 seconds recovery from Durable Object restarts
- [ ] **Bias:** <20% accuracy variation across demographic groups
- [ ] **User Experience:** >4.0/5.0 intervention helpfulness rating

---

## 8. Risk Mitigation

### 8.1 High-Risk Scenarios and Mitigation

| Risk | Likelihood | Impact | Mitigation Strategy |
|------|------------|--------|-------------------|
| **ML Model Accuracy Below 70%** | Medium | High | A/B testing framework, model versioning, fallback models |
| **Performance Degradation Under Load** | Medium | High | Auto-scaling validation, circuit breakers, graceful degradation |
| **Canvas Integration Failures** | Low | High | Multi-environment testing, fallback mechanisms, monitoring |
| **Privacy Compliance Issues** | Low | Critical | Automated compliance testing, legal review, audit logs |
| **Security Vulnerabilities** | Low | Critical | Penetration testing, security scanning, threat modeling |

### 8.2 Contingency Plans

- **Model Performance Issues:** Implement shadow mode testing and gradual rollout
- **Load Testing Failures:** Implement resource quotas and request throttling
- **Canvas Compatibility Issues:** Develop progressive enhancement approach
- **Privacy Violations:** Implement emergency data deletion and consent override

---

This comprehensive test design strategy ensures that Story 5.1's struggle detection system meets all quality, performance, security, and privacy requirements while providing measurable acceptance criteria and automated validation processes.